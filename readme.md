# é¸Ÿä¹‹é“

## é¡¹ç›®æˆå‘˜ä¿¡æ¯

æˆå‘˜å‡æ¥è‡ª NCWU çš„ wqKang å¼€å‘ç»„ï¼š

- 202107927 åº·é—®æ¨µ
- 202109723 å‚…å®¶ä¿Š

## è”ç³»æ–¹å¼

å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡é‚®ä»¶è”ç³»ï¼šwenqiaokang@outlook.com

â€‹	æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªåŸºäºStreamlitçš„äº¤äº’å¼åº”ç”¨ç¨‹åºï¼Œæ—¨åœ¨é€šè¿‡å›¾åƒè¯†åˆ«å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯æé«˜ç”¨æˆ·å¯¹é¸Ÿç±»çš„è®¤çŸ¥å’Œäº†è§£ã€‚åº”ç”¨ç¨‹åºçš„æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼š

1. **å›¾åƒè¯†åˆ«ï¼š** ä½¿ç”¨è®­ç»ƒå’Œä¼˜åŒ–è¿‡çš„YOLOv8æ¨¡å‹å¯¹ç”¨æˆ·ä¸Šä¼ çš„é¸Ÿç±»å›¾ç‰‡è¿›è¡Œå¯¹è±¡æ£€æµ‹ï¼Œå‡†ç¡®è¯†åˆ«å‡ºå›¾ç‰‡ä¸­çš„é¸Ÿç±»ç§ç±»ã€‚

2. **ç§‘æ™®çŸ¥è¯†ç”Ÿæˆï¼š** åˆ©ç”¨ç»è¿‡å¾®è°ƒçš„ChatGLM2è¯­è¨€æ¨¡å‹ï¼Œæ ¹æ®å›¾åƒè¯†åˆ«ç»“æœç”Ÿæˆå…³äºæ£€æµ‹åˆ°çš„é¸Ÿç±»çš„ç§‘æ™®æè¿°ã€‚è¿™ä¸€æ­¥éª¤æ—¨åœ¨æä¾›æ›´å¤šå…³äºè¯†åˆ«é¸Ÿç±»çš„èƒŒæ™¯ä¿¡æ¯å’Œæœ‰è¶£çš„ç§‘å­¦çŸ¥è¯†ã€‚

3. **äº¤äº’å¼ç”¨æˆ·ç•Œé¢ï¼š** é€šè¿‡Streamlitæ„å»ºçš„å‰ç«¯ç•Œé¢ï¼Œç”¨æˆ·å¯ä»¥ç›´è§‚åœ°ä¸Šä¼ å›¾ç‰‡ã€è§¦å‘å›¾åƒè¯†åˆ«è¿‡ç¨‹ï¼Œå¹¶æ¥æ”¶åŒ…æ‹¬é¸Ÿç±»è¯†åˆ«ç»“æœå’Œç›¸å…³ç§‘æ™®ä¿¡æ¯åœ¨å†…çš„åé¦ˆã€‚

4. **çŸ¥è¯†åº“æ•´åˆï¼š** é¡¹ç›®è¿˜æ¢è®¨äº†å¦‚ä½•ç»“åˆæœ¬åœ°çŸ¥è¯†åº“è¿›è¡Œæ›´ç²¾å‡†å’Œä¸ªæ€§åŒ–çš„é—®ç­”æœåŠ¡ã€‚è¿™ä¸€åŠŸèƒ½é€šè¿‡LangChainæ¡†æ¶å’ŒCHATGLMæ¨¡å‹å®ç°ï¼Œè¿›ä¸€æ­¥æ‰©å±•äº†åº”ç”¨ç¨‹åºçš„èƒ½åŠ›ï¼Œå…è®¸ç”¨æˆ·åŸºäºä¸Šä¼ çš„æ–‡æ¡£èµ„æ–™è·å¾—å®šåˆ¶åŒ–çš„é—®ç­”æœåŠ¡ã€‚

â€‹		æ€»ä¹‹ï¼Œè¯¥é¡¹ç›®ç»“åˆäº†æœ€æ–°çš„AIæŠ€æœ¯å’Œç”¨æˆ·å‹å¥½çš„ç•Œé¢è®¾è®¡ï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªæ˜“äºä½¿ç”¨çš„å¹³å°ï¼Œé€šè¿‡å›¾åƒè¯†åˆ«å’Œè¯­è¨€æ¨¡å‹ç”Ÿæˆçš„ç§‘æ™®çŸ¥è¯†ï¼Œå¢è¿›ç”¨æˆ·å¯¹é¸Ÿç±»çš„è®¤è¯†ã€‚è¿™ä¸ä»…å±•ç¤ºäº†AIåœ¨è‡ªç„¶ç•Œæ¢ç´¢å’Œæ•™è‚²é¢†åŸŸçš„æ½œåŠ›ï¼Œä¹Ÿä¸ºæ™®åŠç§‘å­¦çŸ¥è¯†æä¾›äº†æ–°é€”å¾„ã€‚

## é¸Ÿç±»å›¾åƒè¯†åˆ«åŠç§‘æ™®æè¿°

â€‹		åŸºäº Streamlit çš„äº¤äº’å¼åº”ç”¨ç¨‹åºï¼Œç”¨äºå¯¹è±¡æ£€æµ‹ã€‚ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ä»å›¾åƒæ£€æµ‹ç‰©ä½“ï¼Œå¹¶ä½¿ç”¨ YOLOv8 æ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚å½“ç”¨æˆ·ä¸Šä¼ é¸Ÿç±»ç…§ç‰‡ï¼Œç³»ç»Ÿä¼šåˆ©ç”¨ YOLOv8 è¿›è¡Œå›¾åƒè¯†åˆ«ï¼ŒåŒæ—¶ä½¿ç”¨ ChatGLM2 è¯­è¨€æ¨¡å‹æä¾›ç›¸å…³ç§‘æ™®æè¿°ã€‚è¯†åˆ«ç»“æœå’Œä½ç½®ä¼šæ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šï¼Œå¹¶å½¢æˆä¸€ä¸ªé—®é¢˜ï¼Œé€å…¥ ChatGLM2ï¼Œç”Ÿæˆé¸Ÿç±»çš„ç§‘æ™®æè¿°ï¼Œæœ€åé€šè¿‡ç•Œé¢å±•ç¤ºç»™ç”¨æˆ·ã€‚

![](md_images/birds_recongnazation.drawio.png)

â€‹		é¦–å…ˆè¿›å…¥Streamlitçš„å‰ç«¯ç•Œé¢

![](md_images/24f121b5b8c3928434cde9d171863088.png)

â€‹		åœ¨åç«¯ï¼Œé¦–å…ˆåŠ è½½äº†ç»è¿‡å¾®è°ƒçš„ ChatGLM2 è¯­è¨€æ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹ç”¨äºç”Ÿæˆç§‘æ™®æè¿°ã€‚æ¥ç€åŠ è½½äº†é’ˆå¯¹é¸Ÿç±»è¯†åˆ«è¿›è¡Œè®­ç»ƒå’Œå‡æçš„ YOLOv8 ç›®æ ‡è¯†åˆ«æ¨¡å‹ï¼Œç”¨äºè¯†åˆ«é¸Ÿç±»ã€‚

```cmd
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.13it/s]
Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at /home/hk/.cache/modelscope/hub/ZhipuAI/chatglm2-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
weights/detection/yolov8n.pt

```

â€‹		ç”¨æˆ·ç‚¹å‡»â€œå¼€å§‹è¯†åˆ«â€æŒ‰é’®åï¼Œç³»ç»Ÿå°†å¯¹ä¸Šä¼ çš„é¸Ÿç±»ç…§ç‰‡è¿›è¡Œåˆ†æã€‚é¦–å…ˆï¼Œç³»ç»Ÿä½¿ç”¨ YOLOv8 æ¨¡å‹è¯†åˆ«ç…§ç‰‡ä¸­çš„é¸Ÿç±»ç§ç±»ï¼Œå¹¶å°†ç»“æœæ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šã€‚ç„¶åï¼Œç³»ç»Ÿåˆ©ç”¨ ChatGLM2 è¯­è¨€æ¨¡å‹ç”Ÿæˆè¯¥é¸Ÿç±»çš„ç§‘æ™®æè¿°ï¼Œå¹¶å°†æè¿°å±•ç¤ºç»™ç”¨æˆ·ã€‚è¿™æ ·ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ç³»ç»Ÿäº†è§£ç…§ç‰‡ä¸­é¸Ÿç±»çš„ç§ç±»ä»¥åŠç›¸å…³çš„ç§‘å­¦çŸ¥è¯†ã€‚

![](md_images/image-20240223142640248.png)

â€‹		åœ¨è¿™ä¸€æ­¥ï¼Œç³»ç»Ÿä½¿ç”¨ YOLOv8 æ¨¡å‹å¯¹ä¸Šä¼ çš„é¸Ÿç±»ç…§ç‰‡è¿›è¡Œè¯†åˆ«ã€‚é€šè¿‡è¯¥æ¨¡å‹ï¼Œç³»ç»Ÿèƒ½å¤Ÿç¡®å®šç…§ç‰‡ä¸­é¸Ÿç±»çš„åç§°ä»¥åŠå®ƒä»¬åœ¨å›¾ç‰‡ä¸­çš„ç›¸å¯¹ä½ç½®ã€‚è¿™äº›è¯†åˆ«ç»“æœå°†è¢«ç”¨äºåç»­çš„å¤„ç†ï¼Œä¾‹å¦‚ç”Ÿæˆç§‘æ™®æè¿°æˆ–åœ¨ç•Œé¢ä¸Šå±•ç¤ºç»™ç”¨æˆ·ã€‚

```cmd
0: 640x640 1 BANANAQUIT, 13.5ms
Speed: 8.0ms preprocess, 13.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)
{'BANANAQUIT': 1}

```

ä»¥ä¸‹æ˜¯chatglmçš„å®˜æ–¹è°ƒç”¨æ–¹å¼

```python
from transformers import AutoTokenizer, AutoModel
tokenizer = AutoTokenizer.from_pretrained("THUDM/chatglm2-6b", trust_remote_code=True)
model = AutoModel.from_pretrained("THUDM/chatglm2-6b", trust_remote_code=True, device='cuda')
model = model.eval()
response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
print(response)
ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚
response, history = model.chat(tokenizer, "æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ", history=history)
print(response)
æ™šä¸Šç¡ä¸ç€å¯èƒ½ä¼šè®©ä½ æ„Ÿåˆ°ç„¦è™‘æˆ–ä¸èˆ’æœ,ä½†ä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥å¸®åŠ©ä½ å…¥ç¡çš„æ–¹æ³•:

1. åˆ¶å®šè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨:ä¿æŒè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨å¯ä»¥å¸®åŠ©ä½ å»ºç«‹å¥åº·çš„ç¡çœ ä¹ æƒ¯,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚å°½é‡åœ¨æ¯å¤©çš„ç›¸åŒæ—¶é—´ä¸ŠåºŠ,å¹¶åœ¨åŒä¸€æ—¶é—´èµ·åºŠã€‚
2. åˆ›é€ ä¸€ä¸ªèˆ’é€‚çš„ç¡çœ ç¯å¢ƒ:ç¡®ä¿ç¡çœ ç¯å¢ƒèˆ’é€‚,å®‰é™,é»‘æš—ä¸”æ¸©åº¦é€‚å®œã€‚å¯ä»¥ä½¿ç”¨èˆ’é€‚çš„åºŠä¸Šç”¨å“,å¹¶ä¿æŒæˆ¿é—´é€šé£ã€‚
3. æ”¾æ¾èº«å¿ƒ:åœ¨ç¡å‰åšäº›æ”¾æ¾çš„æ´»åŠ¨,ä¾‹å¦‚æ³¡ä¸ªçƒ­æ°´æ¾¡,å¬äº›è½»æŸ”çš„éŸ³ä¹,é˜…è¯»ä¸€äº›æœ‰è¶£çš„ä¹¦ç±ç­‰,æœ‰åŠ©äºç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚
4. é¿å…é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™:å’–å•¡å› æ˜¯ä¸€ç§åˆºæ¿€æ€§ç‰©è´¨,ä¼šå½±å“ä½ çš„ç¡çœ è´¨é‡ã€‚å°½é‡é¿å…åœ¨ç¡å‰é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™,ä¾‹å¦‚å’–å•¡,èŒ¶å’Œå¯ä¹ã€‚
5. é¿å…åœ¨åºŠä¸Šåšä¸ç¡çœ æ— å…³çš„äº‹æƒ…:åœ¨åºŠä¸Šåšäº›ä¸ç¡çœ æ— å…³çš„äº‹æƒ…,ä¾‹å¦‚çœ‹ç”µå½±,ç©æ¸¸æˆæˆ–å·¥ä½œç­‰,å¯èƒ½ä¼šå¹²æ‰°ä½ çš„ç¡çœ ã€‚
6. å°è¯•å‘¼å¸æŠ€å·§:æ·±å‘¼å¸æ˜¯ä¸€ç§æ”¾æ¾æŠ€å·§,å¯ä»¥å¸®åŠ©ä½ ç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚è¯•ç€æ…¢æ…¢å¸æ°”,ä¿æŒå‡ ç§’é’Ÿ,ç„¶åç¼“æ…¢å‘¼æ°”ã€‚

å¦‚æœè¿™äº›æ–¹æ³•æ— æ³•å¸®åŠ©ä½ å…¥ç¡,ä½ å¯ä»¥è€ƒè™‘å’¨è¯¢åŒ»ç”Ÿæˆ–ç¡çœ ä¸“å®¶,å¯»æ±‚è¿›ä¸€æ­¥çš„å»ºè®®ã€‚
```

â€‹		ä»¥ä¸‹ä»£ç ä¼šé¦–å…ˆéå† YOLO æ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œæå–æ£€æµ‹åˆ°çš„é¸Ÿç±»åç§°åŠå…¶æ•°é‡ï¼Œå¹¶æ„å»ºä¸€ä¸ªé—®é¢˜å­—ç¬¦ä¸²ã€‚ç„¶åï¼Œè¯¥é—®é¢˜å­—ç¬¦ä¸²å°†é€šè¿‡ ChatGLM å®˜æ–¹è°ƒç”¨æ–¹å¼ä¼ é€’ç»™è¯­è¨€æ¨¡å‹ï¼Œä»¥è·å–ç”Ÿæˆçš„ç§‘æ™®æè¿°ã€‚æœ€åï¼Œå°†ç”Ÿæˆçš„æè¿°å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—ç¬¦ä¸²å½¢å¼ï¼Œä»¥ä¾¿åœ¨ Streamlit ç•Œé¢ä¸Šæ˜¾ç¤ºç»™ç”¨æˆ·ã€‚

```python
                res = model.predict(uploaded_image,conf=conf)

                # res_class=model.predict(uploaded_image,conf=conf,save=True)
                # print(res_class)
                # print(source_img)


                # åˆå§‹åŒ–ä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨æ£€æµ‹åˆ°çš„å¯¹è±¡åç§°å’Œæ•°é‡
                detected_objects = {}

                # éå†æ£€æµ‹åˆ°çš„æ‰€æœ‰å¯¹è±¡
                for box in res[0].boxes:
                    # è·å–ç±»åˆ«IDï¼Œå¹¶ç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªæ•´æ•°
                    class_id = box.cls.item()  # ä½¿ç”¨.item()æ–¹æ³•ä»å¼ é‡ä¸­è·å–Pythonæ•´æ•°
                    # ä½¿ç”¨nameså­—å…¸è·å–ç±»åˆ«åç§°ï¼Œç¡®ä¿ä½¿ç”¨æ•´æ•°ç´¢å¼•
                    class_name = res[0].names[class_id]

                    # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„å¯¹è±¡æ•°é‡
                    if class_name in detected_objects:
                        detected_objects[class_name] += 1
                    else:
                        detected_objects[class_name] = 1

                print(detected_objects)
                unique_object = list(detected_objects.keys())[0]
                unique_object_str = str(unique_object)

                question="è¯·å‘Šè¯‰æˆ‘äº›å…³äº"+f"{unique_object_str}"+"çš„çŸ¥è¯†å§ï¼Ÿ"
                #å°†é—®é¢˜è¾“é€ç»™å¤§è¯­è¨€æ¨¡å‹
                response=display_answer(llm_tokenizer,llm_model,question)
                response=str(response)
```

â€‹		å½“è·å¾—äº†æ¥è‡ª ChatGLM çš„å“åº”åï¼Œé€šè¿‡ Streamlit å°†å“åº”å­—ç¬¦ä¸²ä¼ é€ç»™å‰ç«¯ç•Œé¢ã€‚

![](md_images/image-20240223142752708.png)

â€‹    	

## å¤šåŠŸèƒ½æ™ºèƒ½é—®ç­”

â€‹		è¿™ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªåŸºäºæœ€æ–°äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œå®ƒç»“åˆäº† LangChain æ¡†æ¶ã€CHATGLM å¯¹è¯æ¨¡å‹å’Œ Streamlit å‰ç«¯æŠ€æœ¯ã€‚é€šè¿‡è¿™ä¸€é›†æˆæ–¹æ¡ˆï¼Œé¡¹ç›®æ—¨åœ¨ä¸ºç”¨æˆ·æä¾›ä¸€ä¸ªé«˜åº¦äº¤äº’å¼çš„å¹³å°ï¼Œä½¿ä»–ä»¬èƒ½å¤Ÿä¸Šä¼ è‡ªå·±çš„æ–‡æ¡£èµ„æ–™ï¼Œå¹¶åŸºäºè¿™äº›èµ„æ–™è·å¾—ç²¾å‡†ã€ç›¸å…³çš„é—®ç­”æœåŠ¡ã€‚

1. **LangChain æ¡†æ¶ï¼š**ä½œä¸ºé¡¹ç›®çš„æŠ€æœ¯æ”¯æŸ±ï¼ŒLangChain æä¾›äº†ä¸è¯­è¨€æ¨¡å‹äº¤äº’çš„å¿…è¦ç»„ä»¶å’ŒæŠ½è±¡ã€‚å®ƒä½¿å¾—å¼€å‘è€…èƒ½å¤Ÿæ–¹ä¾¿åœ°å°†è¯­è¨€æ¨¡å‹è¿æ¥åˆ°å…¶ä»–æ•°æ®æºï¼Œå¹¶åˆ›å»ºèƒ½ä¸ç¯å¢ƒäº’åŠ¨çš„æ™ºèƒ½åº”ç”¨ã€‚
2. **CHATGLM æ¨¡å‹ï¼š**ä½œä¸ºå¯¹è¯å¤„ç†çš„æ ¸å¿ƒï¼ŒCHATGLM æ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±æ–‡åŒè¯­çš„å¯¹è¯è¯­è¨€æ¨¡å‹ï¼Œä¸“ä¸ºå¯¹è¯ä¼˜åŒ–ï¼Œèƒ½åœ¨æœ¬åœ°ç¯å¢ƒä¸­é«˜æ•ˆè¿è¡Œã€‚å®ƒé€šè¿‡å­¦ä¹ ç”¨æˆ·æä¾›çš„æ–‡æ¡£èµ„æ–™ä¸­çš„è¯å‘é‡ï¼Œèƒ½å¤Ÿæä¾›æ›´åŠ è´´è¿‘ç”¨æˆ·éœ€è¦çš„ç­”æ¡ˆã€‚
3. **Streamlit å‰ç«¯ï¼š**é€šè¿‡ Streamlit æ„å»ºçš„ç”¨æˆ·ç•Œé¢ç®€æ´ç›´è§‚ï¼Œå…è®¸ç”¨æˆ·è½»æ¾ä¸Šä¼ æ–‡æ¡£ã€æäº¤æŸ¥è¯¢å¹¶æ¥æ”¶å›ç­”ã€‚Streamlit çš„äº’åŠ¨æ€§å¢å¼ºäº†ç”¨æˆ·ä½“éªŒï¼Œä½¿å¾—éæŠ€æœ¯ç”¨æˆ·ä¹Ÿèƒ½æ— éšœç¢ä½¿ç”¨ç³»ç»Ÿã€‚
4. **æ–‡æ¡£å¤„ç†ä¸çŸ¥è¯†åº“æ„å»ºï¼š**é¡¹ç›®åˆ©ç”¨ç‰¹å®šæ¨¡å‹ï¼ˆ m3e-baseï¼‰å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£ï¼Œå¹¶æ„å»ºè¯å‘é‡ï¼Œå½¢æˆä¸€ä¸ªæœ¬åœ°çŸ¥è¯†åº“ã€‚è¿™ä¸ªçŸ¥è¯†åº“ä¸ä»…åŠ æ·±äº†ç³»ç»Ÿå¯¹ç”¨æˆ·æ–‡æ¡£å†…å®¹çš„ç†è§£ï¼Œä¹Ÿä½¿å¾— CHATGLM èƒ½å¤Ÿåœ¨å›ç­”æ—¶å‚è€ƒè¿™äº›å†…å®¹ï¼Œä»è€Œæä¾›æ›´åŠ ç²¾ç¡®å’Œä¸ªæ€§åŒ–çš„å›ç­”ã€‚



#### å•çº¯çš„llmæ¨¡å‹é—®ç­”

![](md_images/350243974ddbceebb1e74dd6c27d6c2c.png)

å¯ä»¥çœ‹åˆ°ï¼Œå›ç­”æ¯”è¾ƒå®½æ³›ï¼Œåªæ˜¯å•çº¯é€šè¿‡CHATGLMç”Ÿæˆçš„ç­”å¤ã€‚ä¸è¶³ä»¥æ»¡è¶³ä¸€äº›å¯¹äºé¸Ÿç±»çŸ¥è¯†ç›¸å¯¹äº†è§£çš„ç”¨æˆ·ï¼Œä»¥ä¸‹æ˜¯ä¸€ç§æ›´å¥½çš„æ–¹æ¡ˆã€‚

#### ç»“åˆæœ¬åœ°çŸ¥è¯†åº“çš„é—®ç­”

![](md_images/99f7f02f0259b4c367b814e219254e59.png)

ç»“åˆäº†æœ¬åœ°çŸ¥è¯†åº“ï¼Œæ‰€æœ‰çš„å›ç­”éƒ½å˜å¾—æœ‰ä¾æ®ã€‚é€šè¿‡ä»¥ä¸‹ç•Œé¢å¯ä»¥è‡ªå®šä¹‰è‡ªå·±çš„çŸ¥è¯†åº“ï¼ŒåŒ…æ‹¬ç”Ÿæˆæ–°çš„çŸ¥è¯†åº“ï¼Œå‘çŸ¥è¯†åº“ä¸­ä¸Šä¼ æ–‡æ¡£ã€‚

![](md_images/3e66dd7a07dd0e8e8449923f650c94cc.png)







## æ¶‰åŠåˆ°çš„æ¨¡å‹çš„è®­ç»ƒå’Œå¾®è°ƒæ ¸å¿ƒ

### YOLOv8è®­ç»ƒä¸å‡æ

â€‹		å¯¹äºYOLOv8çš„æ¨¡å‹æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯æ¥è‡ªKaggleçš„BIRDS 525 SPECIES- IMAGE CLASSIFICATIONæ•°æ®é›†ï¼Œå…¶ä¸­åŸæœ¬æœ‰525ç§é¸Ÿç±»çš„åˆ†ç±»åŠå›¾åƒï¼Œä½†æ˜¯ç”±äºGPUä»¥åŠè®¾å¤‡æ€§èƒ½é—®é¢˜æˆ‘ä»¬å°±åªæŒ‘é€‰äº†161ç§é¸Ÿç±»ï¼ˆæ•°æ®é›†ä¸­trainã€testã€validå›¾ç‰‡æœ€å¤šçš„ä¼˜å…ˆé€‰æ‹©ï¼‰ï¼Œæ„å»ºåç§°åˆ°ç¼–å·çš„ç´¢å¼•å¹¶å°†å…¶åŠ å·¥ä¸ºcoco2017æ•°æ®é›†çš„æ ¼å¼ã€‚

![](md_images/b2e843712d0fd37fcc51b251088b5834.png)

æ•°æ®é›†æ ¹ç›®å½•æ ¼å¼

```ç›®å½•æ ¼å¼
---images
      --train
      --val
      --test
---labels
      --train
      --val
      --test
```

æ•°æ®é›†æ ‡ç­¾æ ¼å¼

```txt
class_id x_center  y_center  w  h
```

â€‹		å¯¹äº YOLOv8 è¿›è¡Œå‡æçš„ç›®çš„æ˜¯ä¸ºäº†åœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„å‰æä¸‹ï¼Œæé«˜æ¨¡å‹çš„æ¨ç†é€Ÿåº¦å’Œèµ„æºåˆ©ç”¨æ•ˆç‡ï¼Œä»è€Œæ›´å¥½åœ°æ»¡è¶³ä¸åŒåº”ç”¨åœºæ™¯çš„éœ€æ±‚ã€‚ä¸ºäº†ä½¿å¾—YOLOv8ä¿è¯æ¨¡å‹çš„æ•ˆæœï¼Œåœ¨è¿›è¡Œå‡æå‰éœ€è¦è¿›è¡Œçº¦æŸæ€§è®­ç»ƒã€‚

â€‹		åœ¨[tensorboardå¯è§†åŒ–](https://so.csdn.net/so/search?q=tensorboardå¯è§†åŒ–&spm=1001.2101.3001.7020)çº¦æŸè®­ç»ƒè¿‡ç¨‹BNå‚æ•°çš„åˆ†å¸ƒå˜åŒ–ï¼Œéšç€è®­ç»ƒè¿›è¡Œï¼ˆçºµè½´æ˜¯epochï¼‰ï¼ŒBNå±‚å‚æ•°ä¼šé€æ¸ä»æœ€ä¸Šé¢çš„æ­£å¤ªåˆ†å¸ƒè¶‹å‘äº0é™„è¿‘ã€‚ä»¥ä¸‹æ˜¯æ­£å¸¸è®­ç»ƒå’Œç¨€ç–è®­ç»ƒçš„BNå±‚å‚æ•°å€¼çš„åˆ†å¸ƒå›¾ï¼š

![](md_images/b170090ffdf83f3f30a3a1e7a3a142d8.png)

â€‹                                                                                                                         ä¸Šå›¾ä¸ºæ­£å¸¸è®­ç»ƒ

![](md_images/addeb9b1d866517556c0920b53ddc105.png)

â€‹                                                                                                                        ä¸Šå›¾ä¸ºç¨€ç–è®­ç»ƒ

â€‹		ä»¥ä¸Šçš„ç¨€ç–è®­ç»ƒæ˜æ˜¾å¤ªæ—©å°±å…¨åˆ°0äº†ï¼Œè¿™æ ·ä¼šå½±å“ç²¾åº¦ï¼Œå¯ä»¥æŠŠç³»æ•°1e-2æ”¹å°ä¸€ç‚¹1e-3ï¼Œè¿™æ ·ä¼šç¨€ç–çš„æ…¢ä¸€ç‚¹ï¼Œå¦‚ä¸‹å›¾å·¦ä¸º1e-2, å³ä¸º0.3*1e-2



![](md_images/417f99c29e9f7ed58e1ca78a1ca1f666.png)

â€‹		ä¿®æ”¹ç³»æ•°1e-2ä¸º1e-3å°†ä¼šä½¿ç¨€ç–åŒ–çš„é€Ÿåº¦å‡æ…¢ï¼Œå› ä¸ºå®ƒå°†å½±å“åˆ°L1æ­£åˆ™åŒ–çš„å¼ºåº¦ï¼Œä»è€Œå‡ç¼“æƒé‡ç¨€ç–åŒ–çš„é€Ÿåº¦ã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯æƒé‡ç¨€ç–åŒ–è¿‡ç¨‹æ›´åŠ å¹³æ»‘ï¼Œå¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡å°‘å¯¹æ¨¡å‹ç²¾åº¦çš„å½±å“ã€‚

â€‹		å…·ä½“æ¥è¯´ï¼Œé€šè¿‡å°†l1_lambdaçš„è®¡ç®—æ–¹å¼ä¿®æ”¹ä¸º 
$$
l1_lambda = 1e-2 * (1 - 0.9 * epoch / self.epochs)
$$
â€‹		éšç€epochçš„å¢åŠ ï¼Œl1_lambdaçš„å€¼ä¼šä»åˆå§‹å€¼1e-2é€æ¸å‡å°ï¼Œç›´åˆ°è®­ç»ƒç»“æŸã€‚è¿™æ ·å¯ä»¥ä½¿å¾—æ­£åˆ™åŒ–çš„å¼ºåº¦éšç€è®­ç»ƒçš„è¿›è¡Œé€æ¸å‡å°ï¼Œä»è€Œå‡ç¼“æƒé‡ç¨€ç–åŒ–çš„é€Ÿåº¦ã€‚

â€‹		è¿™ç§ä¿®æ”¹çš„å¥½å¤„åœ¨äºï¼Œåœ¨è®­ç»ƒæ—©æœŸï¼Œæ¨¡å‹çš„æƒé‡å°†æ›´å°‘åœ°å—åˆ°æ­£åˆ™åŒ–çš„å½±å“ï¼Œä»è€Œæœ‰åŠ©äºä¿æŒæ¨¡å‹çš„ç²¾åº¦ã€‚è€Œåœ¨è®­ç»ƒåæœŸï¼Œéšç€l1_lambdaé€æ¸å‡å°ï¼Œæ¨¡å‹çš„æƒé‡å°†æ›´å¤šåœ°å‘ç¨€ç–æ–¹å‘æ¼”åŒ–ï¼Œå®ç°æƒé‡çš„ç¨€ç–åŒ–ã€‚è¿™æ ·å¯ä»¥æ›´å¥½åœ°å¹³è¡¡æ¨¡å‹çš„ç¨€ç–åŒ–å’Œç²¾åº¦ä¹‹é—´çš„å…³ç³»ï¼Œæé«˜æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚

#### å‡æä¸»è¦ä»£ç 

```python

from ultralytics import YOLO
import torch
from ultralytics.nn.modules import Bottleneck, Conv, C2f, SPPF, Detect
 
# Load a model
yolo = YOLO("last.pt")
model = yolo.model
 
ws = []
bs = []
 
for name, m in model.named_modules():
    if isinstance(m, torch.nn.BatchNorm2d):
        w = m.weight.abs().detach()
        b = m.bias.abs().detach()
        ws.append(w)
        bs.append(b)
        # print(name, w.max().item(), w.min().item(), b.max().item(), b.min().item())
# keep
factor = 0.8
ws = torch.cat(ws)
threshold = torch.sort(ws, descending=True)[0][int(len(ws) * factor)]
print(threshold)
 
def prune_conv(conv1: Conv, conv2: Conv):
    gamma = conv1.bn.weight.data.detach()
    beta = conv1.bn.bias.data.detach()
    keep_idxs = []
    local_threshold = threshold
    while len(keep_idxs) < 8:
        keep_idxs = torch.where(gamma.abs() >= local_threshold)[0]
        local_threshold = local_threshold * 0.5
    n = len(keep_idxs)
    # n = max(int(len(idxs) * 0.8), p)
    # print(n / len(gamma) * 100)
    # scale = len(idxs) / n
    conv1.bn.weight.data = gamma[keep_idxs]
    conv1.bn.bias.data = beta[keep_idxs]
    conv1.bn.running_var.data = conv1.bn.running_var.data[keep_idxs]
    conv1.bn.running_mean.data = conv1.bn.running_mean.data[keep_idxs]
    conv1.bn.num_features = n
    conv1.conv.weight.data = conv1.conv.weight.data[keep_idxs]
    conv1.conv.out_channels = n
 
    if conv1.conv.bias is not None:
        conv1.conv.bias.data = conv1.conv.bias.data[keep_idxs]
 
    if not isinstance(conv2, list):
        conv2 = [conv2]
 
    for item in conv2:
        if item is not None:
            if isinstance(item, Conv):
                conv = item.conv
            else:
                conv = item
            conv.in_channels = n
            conv.weight.data = conv.weight.data[:, keep_idxs]
 
 
def prune(m1, m2):
    if isinstance(m1, C2f):  # C2f as a top conv
        m1 = m1.cv2
 
    if not isinstance(m2, list):  # m2 is just one module
        m2 = [m2]
 
    for i, item in enumerate(m2):
        if isinstance(item, C2f) or isinstance(item, SPPF):
            m2[i] = item.cv1
 
    prune_conv(m1, m2)
 
 
for name, m in model.named_modules():
    if isinstance(m, Bottleneck):
        prune_conv(m.cv1, m.cv2)
 
seq = model.model
for i in range(3, 9):
    if i in [6, 4, 9]: continue
    prune(seq[i], seq[i + 1])
 
detect: Detect = seq[-1]
last_inputs = [seq[15], seq[18], seq[21]]
colasts = [seq[16], seq[19], None]
for last_input, colast, cv2, cv3 in zip(last_inputs, colasts, detect.cv2, detect.cv3):
    prune(last_input, [colast, cv2[0], cv3[0]])
    prune(cv2[0], cv2[1])
    prune(cv2[1], cv2[2])
    prune(cv3[0], cv3[1])
    prune(cv3[1], cv3[2])
 
for name, p in yolo.model.named_parameters():
    p.requires_grad = True
 
# yolo.val() # å‰ªææ¨¡å‹è¿›è¡ŒéªŒè¯ yolo.val(workers=0)
yolo.export(format="onnx") # å¯¼å‡ºä¸ºonnxæ–‡ä»¶
# yolo.train(data="VOC.yaml", epochs=100) # å‰ªæåç›´æ¥è®­ç»ƒå¾®è°ƒ
 
torch.save(yolo.ckpt, "prune.pt")
print("done")
```

è¿è¡Œå®Œä¼šå¾—åˆ°prune.ptå’Œprune.onnxå¯ä»¥åœ¨netron.appç½‘ç«™æ‹–å…¥onnxæ–‡ä»¶æŸ¥çœ‹æ˜¯å¦å‰ªææˆåŠŸäº†ï¼ŒæˆåŠŸçš„è¯å¯ä»¥çœ‹åˆ°æŸäº›é€šé“æ•°å­—ä¸ºå•æ•°æˆ–è€…ä¸€äº›ä¸è§„å¾‹çš„æ•°å­—ã€‚

![](md_images/ac2dabf32e3a53bf268f047e74ec2874.png)

#### è¿›è¡Œfinetunè®­ç»ƒï¼Œé€šè¿‡æ¢å¤è®­ç»ƒä½¿å¾—æ¨¡å‹mapå›è°ƒã€‚

ä»¥ä¸‹æ˜¯å‡æå®Œåæ¨¡å‹ï¼Œå‰ªæå‰åå„å±‚é€šé“æ•°å¯¹æ¯”

![](md_images/f8a9f0d4e2c8a472e15b29961ec14454.png)

### CHATGLMå¾®è°ƒ

â€‹		æ•°æ®é›†ä¸ºæˆ‘ä»¬è‡ªå·±æ„å»ºï¼Œé€šè¿‡ä½¿ç”¨chatgpt4è¿™ç§æ›´å…ˆè¿›çš„æ™ºèƒ½é—®ç­”æ¨¡å‹ï¼Œç»“åˆæˆ‘ä»¬é€šè¿‡ç½‘ç»œæœå¯»çš„å…³äºé‚£161ç±»é¸Ÿç±»çš„ä¿¡æ¯ã€‚å…ˆè®©chatgpt4å­¦ä¹ æˆ‘ä»¬æœå¯»åˆ°çš„ä¿¡æ¯ç„¶åè®©å…¶æŒ‰ç…§standford-alpacaæ ¼å¼ç”Ÿæˆæ•°æ®é›†å¹¶åˆ‡å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚

```json
{
    "instruction": "ä½ å¥½",
    "input": "",
    "output": "æˆ‘æ˜¯deepbirdsï¼ŒNCWUçš„wqKangå¼€å‘çš„é—®ç­”æœºå™¨äººã€‚"
}
```

#### å¯¹CHATGLMè¿›è¡ŒP-Tuning v2å¾®è°ƒ

â€‹		é€šè¿‡ä¿®æ”¹ptuningé‡Œçš„train.shè„šæœ¬è¿›è¡Œå¾®è°ƒã€‚

â€‹		`PRE_SEQ_LEN` å’Œ `LR` åˆ†åˆ«æ˜¯ soft prompt é•¿åº¦å’Œè®­ç»ƒçš„å­¦ä¹ ç‡ï¼Œå¯ä»¥è¿›è¡Œè°ƒèŠ‚ä»¥å–å¾—æœ€ä½³çš„æ•ˆæœã€‚P-Tuning-v2 æ–¹æ³•ä¼šå†»ç»“å…¨éƒ¨çš„æ¨¡å‹å‚æ•°ï¼Œå¯é€šè¿‡è°ƒæ•´ `quantization_bit` æ¥è¢«åŸå§‹æ¨¡å‹çš„é‡åŒ–ç­‰çº§ï¼Œä¸åŠ æ­¤é€‰é¡¹åˆ™ä¸º FP16 ç²¾åº¦åŠ è½½ã€‚

â€‹		åœ¨é»˜è®¤é…ç½® `quantization_bit=4`ã€`per_device_train_batch_size=1`ã€`gradient_accumulation_steps=16` ä¸‹ï¼ŒINT4 çš„æ¨¡å‹å‚æ•°è¢«å†»ç»“ï¼Œä¸€æ¬¡è®­ç»ƒè¿­ä»£ä¼šä»¥ 1 çš„æ‰¹å¤„ç†å¤§å°è¿›è¡Œ 16 æ¬¡ç´¯åŠ çš„å‰åå‘ä¼ æ’­ï¼Œç­‰æ•ˆä¸º 16 çš„æ€»æ‰¹å¤„ç†å¤§å°ï¼Œæ­¤æ—¶æœ€ä½åªéœ€ 6.7G æ˜¾å­˜ã€‚è‹¥æƒ³åœ¨åŒç­‰æ‰¹å¤„ç†å¤§å°ä¸‹æå‡è®­ç»ƒæ•ˆç‡ï¼Œå¯åœ¨äºŒè€…ä¹˜ç§¯ä¸å˜çš„æƒ…å†µä¸‹ï¼ŒåŠ å¤§ `per_device_train_batch_size` çš„å€¼ï¼Œä½†ä¹Ÿä¼šå¸¦æ¥æ›´å¤šçš„æ˜¾å­˜æ¶ˆè€—ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µé…Œæƒ…è°ƒæ•´ã€‚

æœ¬æ¬¡å¾®è°ƒç»“æœ

```json
{
    "epoch": 160.0,
    "train_loss": 0.22109756726026536,
    "train_runtime": 16630.9567,
    "train_samples": 300,
    "train_samples_per_second": 2.886,
    "train_steps_per_second": 0.18
}
```

####  å¾®è°ƒåæ¨¡å‹çš„è°ƒç”¨

```python
# llm.py
import os
import torch
from transformers import AutoConfig, AutoModel, AutoTokenizer
from IPython.display import display, Markdown, clear_output
from more_gpu import load_model_on_gpus

class ModelLoader:
    def __init__(self, model_path="/home/hk/.cache/modelscope/hub/ZhipuAI/chatglm2-6b",
                 prefix_checkpoint_path="/home/hk/wqKang/ChatGLM2-6B/ptuning/output/adgen-chatglm2-6b-pt-128-2e-2/checkpoint-3000"):
        self.model_path = model_path
        self.prefix_checkpoint_path = prefix_checkpoint_path
        self.config = AutoConfig.from_pretrained(model_path, trust_remote_code=True, pre_seq_len=128)
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        self.model = AutoModel.from_pretrained(model_path, config=self.config, trust_remote_code=True)

        self.load_prefix_state()

    def load_prefix_state(self):
        prefix_state_dict = torch.load(os.path.join(self.prefix_checkpoint_path, "pytorch_model.bin"))
        new_prefix_state_dict = {}
        for k, v in prefix_state_dict.items():
            if k.startswith("transformer.prefix_encoder."):
                new_prefix_state_dict[k[len("transformer.prefix_encoder."):]] = v
        self.model.transformer.prefix_encoder.load_state_dict(new_prefix_state_dict)
        self.model = self.model.half().cuda()
        self.model.transformer.prefix_encoder.float()
        self.model = self.model.eval()

    def get_model(self):
        return self.model
    def get_tokenizer(self):
        return self.tokenizer
# Assuming display_answer is already provided and uses the model and tokenizer correctly


# Instantiate the ModelLoader and make it available for import
model_loader = ModelLoader()

```

```python
from putting import model_loader
import os
import torch
from transformers import AutoConfig, AutoModel, AutoTokenizer
from IPython.display import display, Markdown, clear_output

def display_answer(tokenizer,model, query, history=[]):
    # This is where your existing implementation of display_answer goes
    # For example:
    for response, history in model.stream_chat(tokenizer, query, history=history):
        clear_output(wait=True)
        display(Markdown(response))
    return history

```

```python
from llm import model_loader
# è·å– tokenizer å’Œ model
llm_tokenizer = model_loader.get_tokenizer()
llm_model = model_loader.get_model()
question="è¯·å‘Šè¯‰æˆ‘äº›å…³äº"+f"{unique_object_str}"+"çš„çŸ¥è¯†å§ï¼Ÿ"
response=display_answer(llm_tokenizer,llm_model,question)
response=str(response)
print(response)
```



